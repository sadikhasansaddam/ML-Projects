{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(images):\n",
    "    lab_images = rgb2lab(images)  # Convert RGB to LAB\n",
    "    l_channel = lab_images[..., 0:1] / 100.0  # Normalize L channel\n",
    "    ab_channels = lab_images[..., 1:] / 128.0  # Normalize AB channels\n",
    "    return l_channel, ab_channels\n",
    "\n",
    "# U-Net Generator\n",
    "def build_generator(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(b)\n",
    "    u1 = layers.concatenate([u1, c3], axis=-1)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(u1)\n",
    "    u2 = layers.concatenate([u2, c2], axis=-1)\n",
    "\n",
    "    u3 = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(u2)\n",
    "    u3 = layers.concatenate([u3, c1], axis=-1)\n",
    "\n",
    "    outputs = layers.Conv2D(2, (1, 1), activation='tanh', padding='same')(u3)\n",
    "\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# Custom Metrics Callback for PSNR and SSIM\n",
    "class CustomMetrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, l_val, ab_val):\n",
    "        super().__init__()\n",
    "        self.l_val = l_val\n",
    "        self.ab_val = ab_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        avg_psnr, avg_ssim = evaluate_model(self.model, self.l_val, self.ab_val)\n",
    "        print(f\"  PSNR: {avg_psnr:.2f}, SSIM: {avg_ssim:.4f}\")\n",
    "\n",
    "# Evaluation Function for PSNR and SSIM\n",
    "def evaluate_model(generator, l_test, ab_test):\n",
    "    predictions = generator.predict(l_test)\n",
    "    psnr_scores, ssim_scores = [], []\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        pred_ab = predictions[i] * 128.0\n",
    "        true_ab = ab_test[i] * 128.0\n",
    "        l_channel = l_test[i] * 100.0\n",
    "\n",
    "        pred_lab = np.concatenate((l_channel, pred_ab), axis=-1)\n",
    "        true_lab = np.concatenate((l_channel, true_ab), axis=-1)\n",
    "\n",
    "        pred_rgb = lab2rgb(pred_lab)\n",
    "        true_rgb = lab2rgb(true_lab)\n",
    "\n",
    "        psnr_scores.append(psnr(true_rgb, pred_rgb))\n",
    "        ssim_scores.append(ssim(true_rgb, pred_rgb, multichannel=True, win_size=3, data_range=1))  # Specify data_range\n",
    "\n",
    "    avg_psnr = np.mean(psnr_scores)\n",
    "    avg_ssim = np.mean(ssim_scores)\n",
    "    return avg_psnr, avg_ssim\n",
    "\n",
    "\n",
    "\n",
    "# Training Function\n",
    "def train_model(generator, l_train, ab_train, l_val, ab_val, epochs=10, batch_size=32):\n",
    "    # Prepare TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((l_train, ab_train)).batch(batch_size)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((l_val, ab_val)).batch(batch_size)\n",
    "\n",
    "    # Compile the Generator\n",
    "    generator.compile(\n",
    "        optimizer=optimizers.Adam(1e-4),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train the model with custom metrics callback\n",
    "    history = generator.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=[CustomMetrics(l_val, ab_val)]\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "# Visualization Function\n",
    "def visualize_results(generator, l_test, ab_test, num_samples=5):\n",
    "    predictions = generator.predict(l_test[:num_samples])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        pred_ab = predictions[i] * 128.0\n",
    "        true_ab = ab_test[i] * 128.0\n",
    "        l_channel = l_test[i] * 100.0\n",
    "\n",
    "        pred_lab = np.concatenate((l_channel, pred_ab), axis=-1)\n",
    "        true_lab = np.concatenate((l_channel, true_ab), axis=-1)\n",
    "\n",
    "        pred_rgb = lab2rgb(pred_lab)\n",
    "        true_rgb = lab2rgb(true_lab)\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title('Grayscale')\n",
    "        plt.imshow(l_channel[..., 0], cmap='gray')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('True Color')\n",
    "        plt.imshow(true_rgb)\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Predicted Color')\n",
    "        plt.imshow(pred_rgb)\n",
    "        plt.show()\n",
    "\n",
    "# Plot Training History\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    # Load Dataset\n",
    "    (x_train, _), (x_test, _) = tf.keras.datasets.cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    l_train, ab_train = preprocess_data(x_train)\n",
    "    l_test, ab_test = preprocess_data(x_test)\n",
    "\n",
    "    # Build Generator\n",
    "    input_shape = (32, 32, 1)  # For CIFAR-10\n",
    "    generator = build_generator(input_shape)\n",
    "\n",
    "    # Train Model\n",
    "    history = train_model(generator, l_train, ab_train, l_test[:1000], ab_test[:1000], epochs=10, batch_size=32)\n",
    "\n",
    "    # Plot Training History\n",
    "    plot_training_history(history)\n",
    "\n",
    "    # Visualize Results\n",
    "    visualize_results(generator, l_test, ab_test, num_samples=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
